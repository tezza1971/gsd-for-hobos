---
phase: 05-llm-enhancement
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/llm/api-config.ts
  - src/lib/llm/types.ts
autonomous: true

must_haves:
  truths:
    - User with env var API key sees detection message and can confirm/decline
    - User without env var can enter API key manually
    - User sees endpoint test result before enhancement loop begins
    - User with failed endpoint test sees helpful error and fallback options
  artifacts:
    - path: src/lib/llm/types.ts
      provides: API configuration types
      exports: ["APIConfig", "APIProvider", "ProviderConfig"]
      min_lines: 30
    - path: src/lib/llm/api-config.ts
      provides: Multi-provider API detection and testing
      exports: ["detectAndConfirmAPIConfig", "testEndpoint"]
      min_lines: 150
  key_links:
    - from: src/lib/llm/api-config.ts
      to: process.env
      via: Environment variable detection
      pattern: "process\\.env\\.(OPENAI|ANTHROPIC|OPENROUTER|AZURE)"
    - from: src/lib/llm/api-config.ts
      to: "@clack/prompts"
      via: Interactive confirmation prompts
      pattern: "confirm|password|select"
    - from: src/lib/llm/api-config.ts
      to: "node:fetch"
      via: Endpoint connectivity testing
      pattern: "fetch.*chat/completions"
---

<objective>
Create API configuration module that detects, confirms, and tests multi-provider LLM API keys before entering enhancement loop. Users should experience frictionless detection if they have env vars set, or guided manual entry if not.

Purpose: Establish reliable API connectivity before enhancement loop to fail fast and avoid user confusion about auth errors mid-session.

Output: API configuration types and detection module with multi-provider support (OpenAI, Anthropic, OpenRouter, Azure).
</objective>

<execution_context>
@C:\Users\Terence\code\gsd-open\.claude\get-shit-done\workflows\execute-plan.md
@C:\Users\Terence\code\gsd-open\.claude\get-shit-done\templates\summary.md
</execution_context>

<context>
@C:\Users\Terence\code\gsd-open\.planning\PROJECT.md
@C:\Users\Terence\code\gsd-open\.planning\ROADMAP.md
@C:\Users\Terence\code\gsd-open\.planning\STATE.md
@C:\Users\Terence\code\gsd-open\.planning\phases\05-llm-enhancement\05-CONTEXT.md
@C:\Users\Terence\code\gsd-open\.planning\phases\05-llm-enhancement\05-RESEARCH.md

# Existing patterns
@C:\Users\Terence\code\gsd-open\src\lib\logger.ts
@C:\Users\Terence\code\gsd-open\package.json
</context>

<tasks>

<task type="auto">
  <name>Create API configuration types</name>
  <files>src/lib/llm/types.ts</files>
  <action>
Create TypeScript types for LLM API configuration:

**APIProvider interface:**
- name: string (display name like "OpenAI", "Anthropic")
- envVars: string[] (primary and alternate env var names)
- endpoint: string (default API endpoint URL)
- testModel: string (model to use for connectivity test)

**APIConfig interface:**
- provider: string (provider name)
- apiKey: string (actual key value, memory-only)
- endpoint: string (resolved endpoint URL)
- model: string (default model for this provider)

**ProviderConfig type:**
Hardcoded configs for supported providers (OpenAI, Anthropic, OpenRouter, Azure), each with:
- Primary env var: OPENAI_API_KEY, ANTHROPIC_API_KEY, OPENROUTER_API_KEY, AZURE_OPENAI_API_KEY
- Default endpoints: api.openai.com/v1, api.anthropic.com, openrouter.ai/api/v1, process.env.AZURE_OPENAI_ENDPOINT
- Test models: gpt-4-turbo, claude-3.5-sonnet, anthropic/claude-3.5-sonnet, (user-specified for Azure)

Export all types for use by api-config module and orchestrator.
  </action>
  <verify>TypeScript compiles without errors, types exported correctly</verify>
  <done>src/lib/llm/types.ts exists with APIProvider, APIConfig, ProviderConfig types</done>
</task>

<task type="auto">
  <name>Implement multi-provider API detection and testing</name>
  <files>src/lib/llm/api-config.ts</files>
  <action>
Create API configuration detection module following Research Pattern 1:

**detectAndConfirmAPIConfig() function:**
1. Scan environment variables in priority order: OPENAI_API_KEY, ANTHROPIC_API_KEY, OPENROUTER_API_KEY, AZURE_OPENAI_API_KEY (+ AZURE_OPENAI_ENDPOINT for Azure)
2. For each detected key:
   - Use @clack/prompts confirm() with message: "Found {provider} API key. Use it? ({envVar})", initialValue: true
   - If user confirms, resolve endpoint from provider config
   - Call testEndpoint() with key and endpoint
   - If test succeeds, return { provider, apiKey, endpoint, model }
   - If test fails, offer confirm() to try next provider
3. If no env vars detected or all tests fail:
   - Offer confirm() for manual entry: "No API key detected in environment. Enter manually?", initialValue: false
   - If user confirms, use password() prompt (not stored), select() for provider choice
   - Resolve endpoint, test, return config
4. If all detection fails, return null
5. Handle isCancel() for all prompts (return null on cancel)

**testEndpoint() function:**
1. Build minimal chat completions request: { model: testModel, messages: [{ role: "user", content: "respond with ready" }], max_tokens: 10 }
2. Use native fetch to POST {endpoint}/chat/completions with Authorization: Bearer {apiKey}
3. Parse response, check for choices[0].message.content
4. Return true if successful, false on any error
5. Log verbose details about test attempt and result
6. Use 5-second timeout (DO NOT use exponential backoff here - this is a connectivity test, not a production call)

**Error handling:**
- Catch fetch errors (network issues, DNS failures) and return false from testEndpoint
- Catch JSON parse errors (malformed responses) and return false
- Log all errors with log.verbose() for debugging
- Never throw exceptions - detection should be graceful

Follow established patterns:
- Use log.verbose(), log.info(), log.warn() for user feedback
- Import from @clack/prompts: confirm, password, select, isCancel
- Import picocolors as pc for colored output in messages
- Follow ESM conventions (import with .js extensions)
  </action>
  <verify>npm run build succeeds, TypeScript type checking passes</verify>
  <done>src/lib/llm/api-config.ts exports detectAndConfirmAPIConfig and testEndpoint functions with multi-provider support</done>
</task>

</tasks>

<verification>
Manual verification:
1. Set OPENAI_API_KEY env var, run detection function, confirm it finds and tests OpenAI
2. Unset all env vars, run detection, confirm manual entry flow works
3. Set invalid API key, run detection, confirm test fails gracefully and offers fallback
</verification>

<success_criteria>
- User with valid OPENAI_API_KEY sees: "Found OpenAI API key. Use it?" → Yes → "Testing endpoint..." → Success message
- User with no env vars sees: "No API key detected. Enter manually?" → Yes → Password prompt → Provider selection → Endpoint test
- User with invalid key sees: "Testing endpoint..." → "Test failed. Try alternative?" → Offered next option or manual entry
- All prompts handle Ctrl+C gracefully (isCancel returns null)
</success_criteria>

<output>
After completion, create `.planning/phases/05-llm-enhancement/05-01-SUMMARY.md`
</output>
